{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP9qvsc7lwyPwjAbOjIpAqu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kartik727/ml-projects/blob/master/personalized-news-summarizer/Personalized_News_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Personalized news bot demo\n",
        "\n",
        "This is a demo of the personalized news bot that gathers news articles for the requested categories using Bing News and News.org APIs, and then summarizes them using the Facebook's `bart-large-cnn` model via Huggingface.\n",
        "\n",
        "See the [Github link](https://github.com/kartik727/ml-projects/tree/19d37f3011b66456e917c088924ff89bf27a5b43/personalized-news-summarizer) for complete code including creating a webpage from these articles using Flask and hosting a live version on GCP that updates daily."
      ],
      "metadata": {
        "id": "trATH4yzoDsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q newspaper3k"
      ],
      "metadata": {
        "id": "Jj0F6vrclbjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1cKNugRlSPS"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from requests.models import HTTPError\n",
        "from dataclasses import dataclass\n",
        "from bs4 import BeautifulSoup\n",
        "from bs4.element import Comment\n",
        "from datetime import datetime\n",
        "from dateutil import parser\n",
        "from PIL import Image\n",
        "from urllib.parse import urlparse\n",
        "import newspaper\n",
        "import json\n",
        "# from helpers import api_keys\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy class to hold api keys. In the production code they\n",
        "# are accessed as env variables\n",
        "@dataclass\n",
        "class APIKeys:\n",
        "    HUGGINGFACE_API_KEY : str\n",
        "    BING_API_KEY : str\n",
        "    NEWS_ORG_API_KEY : str\n",
        "\n",
        "api_keys = APIKeys(\n",
        "    HUGGINGFACE_API_KEY = None,\n",
        "    BING_API_KEY = None,\n",
        "    NEWS_ORG_API_KEY = None\n",
        ")"
      ],
      "metadata": {
        "id": "WLej_ZkfmNmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting the parameters\n",
        "\n",
        "All the information about the models used, API endpoints, etc. are present here. API keys are loaded dynamically at runtime from the environment variables"
      ],
      "metadata": {
        "id": "zuhVlQfNr8Xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer_api_params = {\n",
        "    # You can get this for free\n",
        "    'api_key'           : api_keys.HUGGINGFACE_API_KEY,\n",
        "    'endpoint'          : 'https://api-inference.huggingface.co/models/{model}',\n",
        "    'model'             : 'facebook/bart-large-cnn'\n",
        "}\n",
        "\n",
        "news_api_params = {\n",
        "    # You can get this for free (Free tier API)\n",
        "    'bing_search' : {\n",
        "        'api_key'       : api_keys.BING_API_KEY,\n",
        "        'endpoint'      : 'https://api.bing.microsoft.com/{version}/{endpoint}',\n",
        "        'version'       : 'v7.0',\n",
        "        'market'        : 'en-US',\n",
        "        'search_endpt'  : 'search',\n",
        "        'news_endpt'    : 'news'\n",
        "    },\n",
        "\n",
        "    # You can get this for free\n",
        "    'news_org' : {\n",
        "        'api_key'       : api_keys.NEWS_ORG_API_KEY,\n",
        "        'endpoint'      : 'https://newsapi.org/{version}/{endpoint}',\n",
        "        'version'       : 'v2',\n",
        "        'search_endpt'  : 'everything',\n",
        "        'news_endpt'    : 'top-headlines'\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "XQmzP5aEiblL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper classes\n",
        "\n",
        "A lot of boilerplate code around the different APIs that makes them behave in a consistent manner according to our needs and handle common errors without crashing the entire script."
      ],
      "metadata": {
        "id": "pQkJvoC0sPjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KeyNotFoundError(Exception):\n",
        "    pass\n",
        "\n",
        "class NewsSummarizer:\n",
        "    def __init__(self, endpoint:str, model:str, api_key:str):\n",
        "        self._endpoint = endpoint\n",
        "        self._model = model\n",
        "        self._api_key = api_key\n",
        "\n",
        "    @property\n",
        "    def url(self)->str:\n",
        "        return self._endpoint.format(model=self._model)\n",
        "\n",
        "    @property\n",
        "    def headers(self)->dict:\n",
        "        return {'Authorization': f'Bearer {self._api_key}'}\n",
        "\n",
        "    @property\n",
        "    def payload_params(self)->dict:\n",
        "        return {\n",
        "            'max_length' : 2048\n",
        "        }\n",
        "\n",
        "    def batch_summarize(self, articles:list[str])->list[str]:\n",
        "        payload = {'inputs': articles, 'parameters': self.payload_params}\n",
        "        response = requests.post(self.url, headers=self.headers, json=payload)\n",
        "        response.raise_for_status()\n",
        "        return [r['summary_text'] for r in json.loads(response.content)]\n",
        "\n",
        "    def serial_summarize(self, articles:list[str])->list[str]:\n",
        "        summaries = []\n",
        "        for article in articles:\n",
        "            try:\n",
        "                payload = {'inputs': [article], 'parameters': self.payload_params}\n",
        "                response = requests.post(self.url, headers=self.headers, json=payload)\n",
        "                response.raise_for_status()\n",
        "                summaries.append(json.loads(response.content)[0]['summary_text'])\n",
        "            except HTTPError:\n",
        "                summaries.append('Error')\n",
        "        return summaries\n",
        "\n",
        "    def __call__(self, article:str)->str:\n",
        "        return self.batch_summarize([article])[0]"
      ],
      "metadata": {
        "id": "Vu3uI0lyld0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Article:\n",
        "    api_src     : str\n",
        "    url         : str\n",
        "    title       : str\n",
        "    source      : str\n",
        "    time        : datetime\n",
        "    description : str       = 'No description provided'\n",
        "    img_url     : str       = None\n",
        "\n",
        "    def __str__(self):\n",
        "        return f'''Article from {self.api_src} - url:\"{self.url}\", \\\n",
        "        title:\"{self.title}\", src:\"{self.source}\", dt:\"{self.time}\", \\\n",
        "        desc:\"{self.description[:10]}...\", img_url:\"{self.img_url}\"'''\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__str__()\n",
        "\n",
        "    @property\n",
        "    def time_str(self):\n",
        "        return self.time.strftime('%Y-%m-%d %H-%M-%S')\n",
        "\n",
        "class NewsQuery:\n",
        "    CATEGORIES = ['Business', 'Entertainment', 'General',\n",
        "                    'Health', 'Science', 'Technology', 'Sports']\n",
        "    SUBCATEGORIES = {\n",
        "        'Entertainment' : ['Movies and TV', 'Music'],\n",
        "        'Sports' : ['Golf', 'MLB', 'NBA', 'NFL', 'NHL',\n",
        "                    'Soccer', 'Tennis', 'CFB', 'CBB']\n",
        "    }\n",
        "    def __init__(self, category:str, subcategory:str=None):\n",
        "        if category in self.CATEGORIES:\n",
        "            self._category = category\n",
        "        else:\n",
        "            raise ValueError(f'Invalid category: `{category}`')\n",
        "\n",
        "        if subcategory is not None:\n",
        "            if subcategory in self.SUBCATEGORIES[category]:\n",
        "                self._subcategory = subcategory\n",
        "            else:\n",
        "                raise ValueError(f'Invalid subcategory `{subcategory}` for category `{category}`')\n",
        "        else:\n",
        "            self._subcategory = None\n",
        "\n",
        "    @property\n",
        "    def category(self):\n",
        "        return self._category\n",
        "\n",
        "    @property\n",
        "    def subcategory(self):\n",
        "        return self._subcategory"
      ],
      "metadata": {
        "id": "NGplQABV0Usr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class NewsAPI:\n",
        "    api_key: str\n",
        "    endpoint: str\n",
        "\n",
        "    def search(self, query:str, **kwargs)->list[Article]:\n",
        "        raise NotImplementedError('Search method has not been implemented by this class.')\n",
        "\n",
        "    def news(self, category:str, **kwargs)->list[Article]:\n",
        "        raise NotImplementedError('News method has not been implemented by this class.')\n",
        "\n",
        "@dataclass\n",
        "class BingNewsAPI(NewsAPI):\n",
        "    CATEGORIES = {\n",
        "        'Business':{'name':'Business'},\n",
        "        'Entertainment':{'name':'Entertainment',\n",
        "            'subcats': {'Movies and TV':'Entertainment_MovieAndTV', 'Music':'Entertainment_Music'}},\n",
        "        'General':{'name':None},\n",
        "        'Health':{'name':'Health'},\n",
        "        'Science':{'name':'Science'},\n",
        "        'Sports':{'name':'Sports',\n",
        "            'subcats': {'Golf':'Sports_Golf', 'MLB':'Sports_MLB', 'NBA':'Sports_NBA', 'NFL':'Sports_NFL',\n",
        "                        'NHL':'Sports_NHL', 'Soccer':'Sports_Soccer', 'Tennis':'Sports_Tennis',\n",
        "                        'CFB':'Sports_CFB', 'CBB':'Sports_CBB'}},\n",
        "        'Technology':{'name':'Technology'}\n",
        "    }\n",
        "    api_key     : str\n",
        "    endpoint    : str\n",
        "    version     : str = 'v7.0'\n",
        "    market      : str = 'en-US'\n",
        "    search_endpt: str = 'search'\n",
        "    news_endpt  : str = 'news'\n",
        "\n",
        "    @property\n",
        "    def search_url(self)->str:\n",
        "        return self.endpoint.format(version=self.version, endpoint=self.search_endpt)\n",
        "\n",
        "    @property\n",
        "    def news_url(self)->str:\n",
        "        return self.endpoint.format(version=self.version, endpoint=self.news_endpt)\n",
        "\n",
        "    def _parse_article(self, src:str, article_dict:dict)->Article:\n",
        "        try:\n",
        "            date_published = parser.parse(article_dict['datePublished'])\n",
        "        except KeyError:\n",
        "            date_published = None\n",
        "        return Article(\n",
        "            src,\n",
        "            article_dict['url'],\n",
        "            article_dict['name'],\n",
        "            article_dict.get('provider', [dict()])[0].get('name', 'Unknown'),\n",
        "            date_published,\n",
        "            description = article_dict.get('description', 'No description provided'),\n",
        "            img_url = article_dict.get('image', dict()).get('thumbnail', dict()).get('contentUrl')\n",
        "        )\n",
        "\n",
        "    def search(self, query:str, **kwargs)->list[Article]:\n",
        "        params = { 'q': query, 'mkt': self.market }\n",
        "        headers = { 'Ocp-Apim-Subscription-Key': self.api_key }\n",
        "        r = requests.get(self.search_url, headers=headers, params=params, **kwargs)\n",
        "        return [self._parse_article('BingSearch', a) for a in r.json()['webPages']['value']]\n",
        "\n",
        "    def news(self, news_query:NewsQuery, **kwargs)->list[Article]:\n",
        "        params = {'mkt': self.market }\n",
        "        category, subcategory = news_query.category, news_query.subcategory\n",
        "        cat = self.CATEGORIES[category]['name']\n",
        "        if cat is not None:\n",
        "            if subcategory is None:\n",
        "                params['category'] = cat\n",
        "            else:\n",
        "                params['category'] = self.CATEGORIES[category]['subcats'][subcategory]\n",
        "        headers = { 'Ocp-Apim-Subscription-Key': self.api_key }\n",
        "        r = requests.get(self.news_url, headers=headers, params=params, **kwargs)\n",
        "        return [self._parse_article('BingNews', a) for a in r.json()['value']]\n",
        "\n",
        "@dataclass\n",
        "class NewsOrgAPI(NewsAPI):\n",
        "    CATEGORIES = {\n",
        "        'Business':{'name':'business'},\n",
        "        'Entertainment':{'name':'entertainment',\n",
        "            'subcats': {'Movies and TV':'Movies and TV', 'Music':'Music'}},\n",
        "        'General':{'name':'general'},\n",
        "        'Health':{'name':'health'},\n",
        "        'Science':{'name':'science'},\n",
        "        'Sports':{'name':'sports',\n",
        "            'subcats': {'Golf':'Golf', 'MLB':'MLB', 'NBA':'NBA', 'NFL':'NFL',\n",
        "                        'NHL':'NHL', 'Soccer':'Soccer', 'Tennis':'Tennis',\n",
        "                        'CFB':'CFB', 'CBB':'CBB'}},\n",
        "        'Technology':{'name':'technology'}\n",
        "    }\n",
        "    api_key     : str\n",
        "    endpoint    : str\n",
        "    version     : str = 'v2'\n",
        "    language    : str = 'en'\n",
        "    sort_by     : str = 'relevancy'\n",
        "    page_size   : int = 25\n",
        "    search_endpt: str = 'everything'\n",
        "    news_endpt  : str = 'top-headlines'\n",
        "\n",
        "    @property\n",
        "    def search_url(self)->str:\n",
        "        return self.endpoint.format(version=self.version, endpoint=self.search_endpt)\n",
        "\n",
        "    @property\n",
        "    def news_url(self)->str:\n",
        "        return self.endpoint.format(version=self.version, endpoint=self.news_endpt)\n",
        "\n",
        "    def _parse_article(self, article_dict:dict)->Article:\n",
        "        description = 'No description provided.' if article_dict.get('description') is None else article_dict.get('description')\n",
        "        return Article(\n",
        "            'NewsOrg',\n",
        "            article_dict['url'],\n",
        "            article_dict['title'],\n",
        "            article_dict.get('source', dict()).get('name', 'Unknown'),\n",
        "            parser.parse(article_dict['publishedAt']),\n",
        "            description = description,\n",
        "            img_url = article_dict.get('urlToImage')\n",
        "        )\n",
        "\n",
        "    def search(self, query:str, **kwargs)->list[Article]:\n",
        "        params = { 'q': query, 'language': self.language, 'sortBy': self.sort_by, 'pageSize': self.page_size, **kwargs}\n",
        "        headers = { 'X-Api-Key': self.api_key}\n",
        "        r = requests.get(self.search_url, headers=headers, params=params)\n",
        "        r.raise_for_status()\n",
        "        return [self._parse_article(a) for a in r.json()['articles']]\n",
        "\n",
        "    def news(self, news_query:NewsQuery, **kwargs)->list[Article]:\n",
        "        category, subcategory = news_query.category, news_query.subcategory\n",
        "        cat = self.CATEGORIES[category]['name']\n",
        "        params = { 'category': cat, 'language': self.language, 'pageSize': self.page_size, **kwargs}\n",
        "        headers = { 'X-Api-Key': self.api_key}\n",
        "        if subcategory is not None:\n",
        "            subcat = self.CATEGORIES[category]['subcats'][subcategory]\n",
        "            params['q'] = subcat\n",
        "        r = requests.get(self.news_url, headers=headers, params=params)\n",
        "        r.raise_for_status()\n",
        "        return [self._parse_article(a) for a in r.json()['articles']]"
      ],
      "metadata": {
        "id": "ylwajmh_lVMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsFetcher:\n",
        "    def __init__(self, summarizer : NewsSummarizer,\n",
        "            news_apis : list[NewsAPI], /,\n",
        "        ):\n",
        "        self.summarizer = summarizer\n",
        "        self.news_apis = news_apis\n",
        "\n",
        "    def get_results(self, query:str, api:NewsAPI):\n",
        "        return api.search(query)\n",
        "\n",
        "    def _tag_visible(self, element):\n",
        "        if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
        "            return False\n",
        "        if isinstance(element, Comment):\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def _text_from_html(self, body):\n",
        "        soup = BeautifulSoup(body, 'html.parser')\n",
        "        texts = soup.findAll(string=True)\n",
        "        visible_texts = filter(self._tag_visible, texts)\n",
        "        return u' '.join(t.strip() for t in visible_texts)\n",
        "\n",
        "    def _text_from_url(self, url:str):\n",
        "        article = newspaper.Article(url=url, language='en')\n",
        "        article.download()\n",
        "        article.parse()\n",
        "        return article.text\n",
        "\n",
        "    def _get_image(self, img_url:str):\n",
        "        if img_url is None:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            r = requests.get(img_url, stream=True, timeout=2)\n",
        "            return Image.open(r.raw)\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def _filter(self, articles:list[Article])->list[Article]:\n",
        "        filtered = []\n",
        "        for article in articles:\n",
        "\n",
        "            # remove msn articles (can't be summarized properly)\n",
        "            domain = urlparse(article.url).netloc\n",
        "            if domain == 'www.msn.com':\n",
        "                continue\n",
        "\n",
        "            # remove youtube articles\n",
        "            if domain == 'www.youtube.com':\n",
        "                continue\n",
        "\n",
        "            # any other filters go here\n",
        "            # ...\n",
        "\n",
        "            # add to list if not yet filtered out\n",
        "            filtered.append(article)\n",
        "\n",
        "        return filtered\n",
        "\n",
        "    def process_articles(self, articles:list[Article])->list[Article]:\n",
        "        processed_articles = []\n",
        "        for article in self._filter(articles):\n",
        "            try:\n",
        "                webpage = requests.get(article.url, timeout=2)\n",
        "            except:\n",
        "                continue\n",
        "            if webpage.status_code == 200:\n",
        "                try:\n",
        "                    article.article_text = self._text_from_url(article.url)\n",
        "                except:\n",
        "                    article.article_text = self._text_from_html(webpage.content)\n",
        "\n",
        "                # Remove articles that are too small\n",
        "                if len(article.article_text)<100:\n",
        "                    continue\n",
        "\n",
        "                article.image = self._get_image(article.img_url)\n",
        "                processed_articles.append(article)\n",
        "\n",
        "        if len(processed_articles)==0:\n",
        "            print('No articles to process')\n",
        "            return []\n",
        "\n",
        "        texts = [a.article_text for a in processed_articles]\n",
        "\n",
        "        summaries = self.summarizer.serial_summarize(texts)\n",
        "\n",
        "        for pa, summary in zip(processed_articles, summaries):\n",
        "            pa.summary = summary\n",
        "\n",
        "        return processed_articles\n",
        "\n",
        "    def news(self, news_query:NewsQuery, /, *, max_articles:int=10):\n",
        "        all_articles = {}\n",
        "\n",
        "        for news_api in self.news_apis:\n",
        "            article_list = news_api.news(news_query)\n",
        "            for article in article_list:\n",
        "                all_articles[article.url] = article\n",
        "        all_articles = [a for u,a in all_articles.items()][:max_articles]\n",
        "        all_articles = self.process_articles(all_articles)\n",
        "        return all_articles"
      ],
      "metadata": {
        "id": "M3jV47ughN5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating the article data\n",
        "\n",
        "Call the `generate_data` function with the `search_params` argument, which tells the funciton which categories to get news for, and how many articles per category"
      ],
      "metadata": {
        "id": "cMKro_BFsm44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data(search_params:dict):\n",
        "    # Initialize the news summarizer\n",
        "    if summarizer_api_params['api_key'] is not None:\n",
        "        summarizer = NewsSummarizer(**summarizer_api_params)\n",
        "    else:\n",
        "        raise KeyNotFoundError('No API key provided to summarize the news')\n",
        "\n",
        "    # Initialize the news apis\n",
        "    news_apis = []\n",
        "    if news_api_params['news_org']['api_key'] is not None:\n",
        "        news_org_api = NewsOrgAPI(**news_api_params['news_org'])\n",
        "        news_apis.append(news_org_api)\n",
        "    if news_api_params['bing_search']['api_key'] is not None:\n",
        "        bing_api = BingNewsAPI(**news_api_params['bing_search'])\n",
        "        news_apis.append(bing_api)\n",
        "\n",
        "    # Initialize the news fetcher\n",
        "    if len(news_apis) > 0:\n",
        "        news_fetcher = NewsFetcher(summarizer, news_apis)\n",
        "        logging.info('Ready to fetch news')\n",
        "    else:\n",
        "        raise KeyNotFoundError('No API keys provided to get the news')\n",
        "\n",
        "    results = {}\n",
        "    for qi in search_params['categories']:\n",
        "        logging.info(f'Fetching news for {qi}')\n",
        "        query = NewsQuery(qi)\n",
        "        articles = news_fetcher.news(query, max_articles=search_params['num_articles'])\n",
        "        results[qi] = [a for a in articles]\n",
        "        logging.info(f'Fetched {len(articles)} articles for {qi}')\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "xpBXLYNFd6WS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample run of the code\n",
        "\n",
        "Note: You will need to supply your own API keys at the top of the script for this to work"
      ],
      "metadata": {
        "id": "5J6Yv5Qps4Ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_params = {\n",
        "    'categories' : ['General', 'Sports'],\n",
        "    'num_articles' : 5\n",
        "}\n",
        "\n",
        "results = generate_data(search_params)\n",
        "print(results)"
      ],
      "metadata": {
        "id": "rAxd2SijJ1qX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}